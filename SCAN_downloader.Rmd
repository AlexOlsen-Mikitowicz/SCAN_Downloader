---
title: "SCAN_R"
author: "Alex Olsen-Mikitowicz"
date: "4/16/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

library(tidyverse)
library(lubridate)
library(purrr)
library(dplyr)


#you need to install packages for the functions listed in the library call before this will work

#library(riem) 
#pulls automated surface observations stations - commonly found at airports and is limited to weather data

library(RNRCS) 
#Downloads Natural Resources Conservation Service (NRCS) data for sites in the Soil Climate 
# Analysis Network (SCAN) <https://www.wcc.nrcs.usda.gov/scan/>, and Snow Telemetry (SNOTEL and SNOLITE) 
# <https://www.wcc.nrcs.usda.gov/snow/> networks. Metadata can be returned for all sites in the NRCS' Air and 
# Water Data Base (AWDB) <https://www.wcc.nrcs.usda.gov/report_generator/AWDB_Network_Codes.pdf>.

library(metScanR) 
#A tool for locating, mapping, and gathering environmental data and metadata, worldwide. 
# Users can search for and filter metadata from > 157,000 environmental monitoring stations among 219 
# countries/territories and >20 networks/organizations via elevation, location, active dates, elements 
# measured (e.g., temperature, precipitation), country, network, and/or known identifier. Future updates to the 
# package will allow the user to obtain datasets from stations within the database

getwd()

scan_sites <- getId(id="SCAN")

scan_sites1 <- grabNRCS.meta("SCAN")

scan_sites2 <- do.call(what = rbind, args = scan_sites1)


scan_id <- scan_sites2 %>%
  select(site_id) %>%
  separate(., col = site_id, into = c("Network", "ID"), sep = ":") %>%
  select(ID)

#can be used to subset the scan stations, change the slice(x:y), 
scan_test <- scan_id %>%
  slice(1:3) %>%
  as_vector()

#function for downloading all scan data. If you want to change the date range change it below (ymd format). If you want to change the time step change "daily" to "hourly" for example.
scan_downloader = function(scan_site) {
 
  site_data = grabNRCS.data(network = "SCAN", site_id = scan_site, timescale = "daily", "2019-01-1", "2019-01-2") %>%
    mutate(SCAN_ID = scan_site)
  return(site_data)
}


#maps or iterates the function defined above with each site id defined in scan_id dataframe
#test_scan_sites <- map_dfr(scan_test, scan_downloader)

all_scan_sites <- map_dfr(scan_id, scan_downloader)

#sets the directory to your current working directory
dir <- getwd()
#use below code if you want to set your own directory, uncomment line below and delete or uncomment above line
#dir <- "paste your desired working directory here"
write_csv(all_scan_sites, file.path(dir, "scan_sites.csv"))

#example script for downloading from one SCAN station
#test_scan_download <- grabNRCS.data(network = "SCAN", site_id = 2229, timescale = "daily", DayBgn = "2019-01-1", DayEnd = "2019-01-2")



```

